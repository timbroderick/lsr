setwd("~/anaconda3/envs/lsr/chapter_5_descriptive")
# set directory
setwd("~/anaconda3/envs/lsr/chapter_5_descriptive")
df <- read_csv("aflsmall.Rdata")
# load libraries
library(tidyverse)
#library('readxl')
library("RPostgreSQL")
options("scipen" = 10)
df <- read_csv("aflsmall.Rdata")
df <- load("aflsmall.Rdata")
# load data
load("aflsmall.Rdata")
class(afl.finalists)
afl.finalists
afl.margins
class(afl.margins)
df <- afl.margins
hist(afl.margins, breaks=10, main="Histogram", col="green")
sum(df)
sum(df[1:5])
# find mean for first five
mean( sum(df[1:5]) )
# find mean for first five
mean( df[1:5] )
median( df[1:5] )
# trimmed mean (10% trimmed mean = dropping 10% from top and bottom)
dataset <- c( -15,2,3,4,5,6,7,8,9,12 )
mean(dataset)
median(dataset)
mean( dataset, trim = .1)
?mean
mean( dataset, trim-.05)
mean( dataset, trim = .05)
# making our typing easier
dfin <- afl.finalists
mode(dfin)
head(dfin)
summary(dfin)
dfsum <- dfin %>%
group_by() %>%
summarize(count=n())
# making our typing easier
dfin <- as.data.frame(afl.finalists)
View(dfin)
colnames(dfin) <- c("places")
head(dfin)
summary(dfin)
dfsum <- dfin %>%
group_by(places) %>%
summarize(count=n())
View(dfsum)
table(afl.finalists)
unique(dfin$places)
# there are 17 unique places
table(dfin)
# finding mode
names(dfin)[which(y==max(dfin))]
# finding mode
names(dfin)[which(dfin==max(dfin))]
max(dfin)
dfsum <- dfin %>%
group_by(places) %>%
summarize(count=n()) %>%
sort(count)
names(table(dfin))[table(dfin)==max(table(dfin))]
dfsum <- dfin %>%
group_by(places) %>%
summarize(count=n()) %>%
arrange(count)
View(dfsum)
dfsum <- dfin %>%
group_by(places) %>%
summarize(count=n()) %>%
arrange(count,desc)
dfsum <- dfin %>%
group_by(places) %>%
summarize(count=n()) %>%
arrange(-count)
View(dfsum)
# mode of dfin = top one
slice(dfsum[1])
# mode of dfin = top one
dfsum[1]
# mode of dfin = top one
dfsum(1)
# mode of dfin = top one
head(dfsum,1)
# let's do this for margin
df <- as.data.frame(df)
# let's do this for margin
df <- as.data.frame(df) %>% colnames(df) <- c("margins")
colnames(df) <- c("margins")
# and gets dropped in group_by
dfsum2 <- df %>%
group_by(margins) %>%
summarize(count=n()) %>%
arrange(-count) # - is order descending
# mode of dfin = top one
head(dfsum2,1)
# calculating range
max(df$margins)
min(df$margins)
mean(df$margins)
median(df$margins)
range(df$margins)
# then there's summary
summary(df)
# IQR
quantile(df$margin, c(.25,.75))
# IQR
quantile(df$margin, c(.25,.50,.75))
median(df$margins)
iqr(df$margin)
IQR(df$margin)
# basically, calculates the .25 and .75, then subtracts them
quantile(df$margin,.75) - quantile(df$margin,.25)
# IQR
quantile(df$margins, c(.25,.50,.75))
median(df$margins)
IQR(df$margins)
# basically, calculates the .25 and .75, then subtracts them
quantile(df$margins,.75) - quantile(df$margins,.25)
# deviation from the mean
sd(df$margins)
?sd
sd(c(56, 31,56,8,32))
X <- c(56, 31,56,8,32)   # enter the data
X.bar <- mean( X )       # step 1. the mean of the data
AD <- abs( X - X.bar )   # step 2. the absolute deviations from the mean
AAD <- mean( AD )        # step 3. the mean absolute deviations
print( AAD )             # print the results
AAD
?abs
MedAAD <- median(AD)     # optionally, we can find the median of the absolute deviations
MedAAD
var(df$margins)
sd(df$margins)
# variance without
mean( (df$margins - mean(df$margins) )^2)
var(df$margins)
?^
var(df$margins)
sd(df$margins)
sqrt( var(df$margins) )
# median and mean absolute deviation
mean( abs(df$margins - mean(df$margins)) )
median( abs(df$margins - median(df$margins)) )
AAD
mad(df$margins)
mad(df$margins, constant = 1)
mad(df$margins, constant = 1.4826)
# let's get everything and find some outliers
dfbind <- setNames(data.frame(matrix(ncol = 12, nrow = 1)), # of columns must match
c("count","q25","q50","q75","iqr","cut_off","lower","upper","mean","count_lower","count_upper"))
dfbind$count <- as.integer(nrow(df))
dfbind$q25 <- round( quantile(df$margins, .25, na.rm=TRUE),2)
dfbind$q50 <- round( quantile(df$margins, .50, na.rm=TRUE),2)
dfbind$q75 <- round( quantile(df$margins, .75, na.rm=TRUE),2)
# now find the interquartile range
dfbind$iqr <- IQR(df$margins)
# calculate the outlier cutoff, which is 1.5 of the iqr
dfbind$cut_off <- round( dfbind$iqr * 1.5,2)
# that means anything below the lower bound or higher than the upper bound is considered an outlier
dfbind$lower <- dfbind$q25 - dfbind$cut_off
dfbind$upper <- dfbind$q75 + dfbind$cut_off
dfbind$mean <- round( mean(df$margins, na.rm=TRUE) ,2)
dfbind$median <- round( median(df$margins, na.rm=TRUE) ,2)
dfbind$count_lower <- as.integer( nrow( filter(df,margins <= dfbind$lower) ) )
dfbind$count_upper <- as.integer( nrow( filter(df,margins > dfbind$upper) ) )
View(dfbind)
# let's get everything and find some outliers
dfbind <- setNames(data.frame(matrix(ncol = 11, nrow = 1)), # of columns must match
c("count","q25","q50","q75","iqr","cut_off","lower","upper","mean","count_lower","count_upper"))
dfbind$count <- as.integer(nrow(df))
dfbind$q25 <- round( quantile(df$margins, .25, na.rm=TRUE),2)
dfbind$q50 <- round( quantile(df$margins, .50, na.rm=TRUE),2)
dfbind$q75 <- round( quantile(df$margins, .75, na.rm=TRUE),2)
# now find the interquartile range
dfbind$iqr <- IQR(df$margins)
# calculate the outlier cutoff, which is 1.5 of the iqr
dfbind$cut_off <- round( dfbind$iqr * 1.5,2)
# that means anything below the lower bound or higher than the upper bound is considered an outlier
dfbind$lower <- dfbind$q25 - dfbind$cut_off
dfbind$upper <- dfbind$q75 + dfbind$cut_off
dfbind$mean <- round( mean(df$margins, na.rm=TRUE) ,2)
dfbind$median <- round( median(df$margins, na.rm=TRUE) ,2)
dfbind$count_lower <- as.integer( nrow( filter(df,margins <= dfbind$lower) ) )
dfbind$count_upper <- as.integer( nrow( filter(df,margins > dfbind$upper) ) )
View(dfbind)
56-36.6
?abs
# Mean absolute deviation
# average distance between each data point and the mean
# The mean absolute deviation show the amount of deviation (variation)
# that occurs around the mean score.
# We use the absolute value of the numbers because negatives
abs(-5)
# or
mean ( abs( X - mean( X ) ) )
AAD # average (mean) absolute deviation
# so for margins
mean( abs(df$margins - mean(df$margins)) )
# variance
mean( (df$margins - mean(df$margins) )^2)
# Instead of absolute value, variance squares (^2) the results to get positive values
# a large number means the values are very spread out
# a smaller number means the values are closer to the mean
# variance is also used for finding sd
sqrt( var(df$margins) )
sd(df$margins) # square root of the variance
# median absolute deviation is the same but with median
median( abs(df$margins - median(df$margins)) )
mad(df$margins, constant = 1.4826)
# median absolute deviation is the same but with median
# this is handy to identify outliers when the mean is overly affected by them
median( abs(df$margins - median(df$margins)) )
mad(df$margins, constant = 1.4826)
?mad
# so for margins
mean( abs(df$margins - mean(df$margins)) )
# the mad functionallows a consistency constant.
# This modification will ensure that for large samples the MAD provides a good
# estimate of the standard deviation (more formally, the MAD becomes a
# consistent estimator of the population standard deviation)
# https://eurekastatistics.com/using-the-median-absolute-deviation-to-find-outliers/s
mad(df$margins, constant = 1.4826)
# skewness and kurtosis
# https://www.r-bloggers.com/measures-of-skewness-and-kurtosis/
library(moments)
# skewness and kurtosis
# https://www.r-bloggers.com/measures-of-skewness-and-kurtosis/
install.packages(moments)
# skewness and kurtosis
# https://www.r-bloggers.com/measures-of-skewness-and-kurtosis/
install.packages("moments")
library(moments)
?moments
skewness(df$margins)
kurtosis(df$margins)
# summary stats
blowouts <-  afl.margins > 50
blowouts
summary(blowouts)
load("clinicaltrial.Rdata")
summary(clin.trial)
# get describe stats
count(clin.trial$mood.gain)
# get describe stats
n(clin.trial$mood.gain)
# get describe stats
nrow(clin.trial$mood.gain)
# get describe stats
NROW(clin.trial$mood.gain)
# get describe stats
NROW(clin.trial$mood.gain)
mean(clin.trial$mood.gain)
sd(clin.trial$mood.gain)
round( mean(clin.trial$mood.gain),2)
round( sd(clin.trial$mood.gain),2)
round( median(clin.trial$mood.gain),2)
round( mean(clin.trial$mood.gain,trim=.1),2)
round( mad(clin.trial$mood.gain),2)
round( min(clin.trial$mood.gain),2)
round( max(clin.trial$mood.gain),2)
round( range(clin.trial$mood.gain),2)
round( skewness(clin.trial$mood.gain),2)
round( kurtosis(clin.trial$mood.gain),2)
round( mean_se(clin.trial$mood.gain),2)
1.01-0.76
?stderr
meanerr <- function(x) sd(x)/sqrt(length(x))
round( meanerr(clin.trial$mood.gain),2)
#alternately, let's try the describe packate
install.packages("psych")
#alternately, let's try the psych packate
#install.packages("psych")
library(psych)
describeBy( x=clin.trial, group=clin.trial$therapy )
# could also do
by( data=clin.trial, INDICES=clin.trial$therapy, FUN=summary )
aggregate( formula = mood.gain ~ drug + therapy,  # mood.gain by drug/therapy combination
data = clin.trial,                     # data is in the clin.trial data frame
FUN = mean                             # print out group means
)
# standardized scores or z scores
pnorm(clin.trial$mood.gain)
?pnorm
# correlation
load("parenthood.Rdata")
describe.by(parenthood)
describeBy(parenthood)
summary(parenthood)
cor( x = parenthood$dan.sleep, y = parenthood$dan.grump )
# doing the whole data frame produces a matrix
cor( x = parenthood )
